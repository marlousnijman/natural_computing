{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical Evolutionary Strategies for Atari Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DQN\n",
    "from AtariCES import AtariCES as CAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = \"SpaceInvaders\"\n",
    "render = False\n",
    "max_step = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary Strategy Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = [0.5,0.01] # [start, end] or value\n",
    "n_offspring = 25\n",
    "n_parents = 5\n",
    "iterations = 10\n",
    "adaptive_type = 'log' #'constant', 'linear', 'exp', 'log'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAF = CAF(game, render, max_step=max_step, sigma=sigma,\n",
    "        n_parents=n_parents, n_offspring=n_offspring, iterations=iterations, adaptive_type=adaptive_type)\n",
    "        \n",
    "env, n_actions, actions_meanings, state_dim = CAF.initiate_env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 6\n",
      "Action meanings: ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
      "State dimensions: (4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of actions: {n_actions}\")\n",
    "print(f\"Action meanings: {actions_meanings}\")\n",
    "print(f\"State dimensions: {state_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 32)        8224      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 20, 20, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 9, 9, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 7, 7, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 6)                24        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,689,918\n",
      "Trainable params: 1,688,562\n",
      "Non-trainable params: 1,356\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DQN(n_actions=n_actions)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAF.set_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [09:00<00:00, 21.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1275. 1160. 1125. 1075.  980.  960.  960.  960.  955.  850.  800.  785.\n",
      "  780.  750.  725.  720.  690.  685.  665.  590.  560.  140.   20.    0.\n",
      "    0.]\n",
      "best reward: 1275.0\n",
      "Iteration:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:55<00:00, 21.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1315.  960.  935.  870.  760.  720.  570.  550.  545.  520.  445.  420.\n",
      "  285.  275.  235.  195.  190.  165.   95.   80.   50.   40.   20.   15.\n",
      "    0.]\n",
      "best reward: 1315.0\n",
      "Iteration:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:54<00:00, 21.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1300. 1185. 1170.  960.  960.  915.  890.  890.  805.  750.  745.  730.\n",
      "  720.  720.  600.  590.  445.  435.  355.  195.   95.   90.    0.    0.\n",
      "    0.]\n",
      "best reward: 1300.0\n",
      "Iteration:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:54<00:00, 21.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1460. 1420. 1385. 1330. 1285. 1210. 1130. 1025.  770.  765.  720.  625.\n",
      "  620.  620.  545.  530.  460.  370.  345.  305.  180.   25.    0.    0.\n",
      "    0.]\n",
      "best reward: 1460.0\n",
      "Iteration:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:54<00:00, 21.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1315. 1310. 1265. 1235. 1195. 1070. 1070. 1025. 1020.  930.  870.  835.\n",
      "  835.  820.  815.  810.  760.  720.  715.  695.  515.  450.  430.  315.\n",
      "  200.]\n",
      "best reward: 1315.0\n",
      "Iteration:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:55<00:00, 21.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1405. 1335. 1315. 1315. 1315. 1280. 1255. 1100.  995.  960.  920.  855.\n",
      "  795.  765.  755.  755.  735.  710.  710.  675.  495.  325.  320.  110.\n",
      "   40.]\n",
      "best reward: 1405.0\n",
      "Iteration:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:56<00:00, 21.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1715. 1330. 1225. 1200. 1115. 1085. 1070.  960.  930.  915.  905.  900.\n",
      "  820.  735.  670.  660.  630.  540.  290.  150.  140.  125.   45.   25.\n",
      "    0.]\n",
      "best reward: 1715.0\n",
      "Iteration:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:55<00:00, 21.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1560. 1415. 1340. 1315. 1315. 1305. 1300. 1250. 1130. 1125.  915.  825.\n",
      "  815.  755.  735.  730.  730.  690.  675.  615.  590.  525.  490.  460.\n",
      "  300.]\n",
      "best reward: 1560.0\n",
      "Iteration:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:55<00:00, 21.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1410. 1410. 1315. 1315. 1035. 1005.  985.  970.  960.  960.  865.  860.\n",
      "  840.  805.  765.  660.  655.  600.  545.  430.  355.  340.  250.  230.\n",
      "    0.]\n",
      "best reward: 1410.0\n",
      "Iteration:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [08:56<00:00, 21.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: [1360. 1330. 1315. 1225. 1140. 1105. 1095.  970.  960.  960.  955.  895.\n",
      "  820.  805.  790.  760.  750.  720.  610.  540.  470.  425.  230.   95.\n",
      "   70.]\n",
      "best reward: 1360.0\n"
     ]
    }
   ],
   "source": [
    "theta, rewards = CAF.CES()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Final Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAF.show_last(theta, max_step=max_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.01: hoogste score laatste iteratie = 0, hoogste score over alle iteraties = 0\n",
    "0.1: hoogste score laatste iteratie = 0, hoogste score over alle iteraties = 0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b3a8bbf377d4ca1530282dfc9385f115aa599de11785bf312b469670b0fb4fa"
  },
  "kernelspec": {
   "display_name": "Python [conda env:natcom]",
   "language": "python",
   "name": "conda-env-natcom-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
